{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "\n",
    "# Run anaconda prompt as admin (search \"anaconda prompt\" in the search bar on windows and right click to run as admin)\n",
    "# Run the following lines in the anaconda cmd to install missing dependencies\n",
    "# Conda install keras\n",
    "# If any other module is missing, try conda install \"name of module\"\n",
    "\n",
    "# If anaconda is not installed, follow this guide: https://docs.anaconda.com/anaconda/install/windows/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import all packages/libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from concurrent import futures\n",
    "import threading\n",
    "\n",
    "# The following is important for the model building itself\n",
    "import keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class directory:\n",
    "    closed_v = os.path.join (directory , 'Closed_Valve')\n",
    "    open_v = os.path.join (directory , 'Open_Valve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hypParam:\n",
    "    batch_size = 8\n",
    "    nr_epochs = 45\n",
    "    verbose = 1\n",
    "    lr = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelName:\n",
    "    model_name = 'mitral_valve_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is \"labeled\" in the sense that there are two folders which contain pictures of a closed valve and an open valve\n",
    "# This snippet of code will navigate to those folders and read in all the pictures in jpg format\n",
    "Closed_Valve = glob.glob (directory.closed_v + '/*.jpg' )\n",
    "Open_Valve = glob.glob (directory.open_v + '/*.jpg' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframe, where file and label are used as input array and list respectively, in train_test_split.\n",
    "\n",
    "df = pd.DataFrame ({\n",
    "    'file' : Closed_Valve + Open_Valve,\n",
    "    'label' : ['Closed_Valve'] * len (Closed_Valve)  +  ['Open_Valve'] * len (Open_Valve) \n",
    "     }). sample (frac = 1 , random_state = 0 ). reset_index (drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,) (36,) (46,)\n",
      "Train: Counter({'Open_Valve': 76, 'Closed_Valve': 68}) \n",
      "Validation Set: Counter({'Open_Valve': 19, 'Closed_Valve': 17}) \n",
      " Test Set: Counter({'Open_Valve': 26, 'Closed_Valve': 20})\n"
     ]
    }
   ],
   "source": [
    "# Gather the image from its directory and insert into main memory for subsequent processing \n",
    "# Split the dataset into three parts.\n",
    "# 60 percent of the whole dataset is reserved as a training set, while the testing and validation set are 20 percent each\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = train_test_split(df['file'].values,\n",
    "                                                                      df['label'].values, \n",
    "                                                                      test_size=0.2, random_state=42)\n",
    "\n",
    "x_train, y_val, x_test, y_val_test = train_test_split(x_train, x_test, \n",
    "                                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "# In order - nr of samples, number pictures in validation set and nr of pictures in test set\n",
    "print(x_train.shape, y_val.shape, y_train.shape)\n",
    "print('Train:', Counter(x_test), '\\nValidation Set:', Counter(y_val_test), '\\n Test Set:', Counter(y_test))\n",
    "\n",
    "# A quick google search yielded the dimensions 224x224 for width and height as default input for CNN models\n",
    "img_dims = (224, 224)\n",
    "\n",
    "# Accelarating data loading by reading in image data on parallell threads. idx = index\n",
    "def get_img_data_parallel(idx, img, total_imgs):\n",
    "    if idx % 100 == 0 or idx == (total_imgs - 1):\n",
    "        # Utilize the threading.current_thread() function in order to determine which thread has performed this task.\n",
    "        print('{}: Processing image number: {}'.format(threading.current_thread().name,\n",
    "                                                  idx))\n",
    "    img = cv2.imread(img)\n",
    "    \n",
    "    # There are several interpolation methods, this uses a bicubic interpolation over 4Ã—4 pixel neighborhood\n",
    "    img = cv2.resize(img, dsize=img_dims, \n",
    "                     interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Reads the image in as an array\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    return img\n",
    "\n",
    "# https://tutorialedge.net/python/concurrency/python-threadpoolexecutor-tutorial/\n",
    "# Instantiating our own threadpoolexecutor\n",
    "executor = futures.ThreadPoolExecutor(max_workers=None)\n",
    "\n",
    "\n",
    "# This returns a list with images and their corresponding indexes\n",
    "# Enumerate: for each index and image Iterate over indices and items of a list\n",
    "x_data_inp = [(idx, img, len(x_train)) for idx, img in enumerate(x_train)]\n",
    "y_val_inp = [(idx, img, len(y_val)) for idx, img in enumerate(y_val)]\n",
    "test_data_inp = [(idx, img, len(y_train)) for idx, img in enumerate(y_train)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Train Images:\n",
      "\n",
      "ThreadPoolExecutor-0_0: Processing image number: 0\n",
      "ThreadPoolExecutor-0_31: Processing image number: 100\n",
      "ThreadPoolExecutor-0_1: Processing image number: 143\n"
     ]
    }
   ],
   "source": [
    "# Load training images into main memory\n",
    "\n",
    "print('\\nLoading Train Images:\\n')\n",
    "# \"executor.map() function returns results in the same order as the list of data we gave it to process\"\n",
    "x_data_map = executor.map(get_img_data_parallel, \n",
    "                        [record[0] for record in x_data_inp],\n",
    "                        [record[1] for record in x_data_inp],\n",
    "                        [record[2] for record in x_data_inp])\n",
    "x_data = np.array(list(x_data_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Validation Images:\n",
      "\n",
      "ThreadPoolExecutor-0_17: Processing image number: 0\n",
      "ThreadPoolExecutor-0_8: Processing image number: 35\n"
     ]
    }
   ],
   "source": [
    "# Load the validation images into the main memory \n",
    "print('\\nLoading Validation Images:\\n')\n",
    "\n",
    "# Quote on executor.map(): \"It does all the hard work of splitting up the list, \n",
    "# sending the sub-lists off to each child process, running the child processes, \n",
    "# and combining the results\"\n",
    "y_val_map = executor.map(get_img_data_parallel, \n",
    "                        [record[0] for record in y_val_inp],\n",
    "                        [record[1] for record in y_val_inp],\n",
    "                        [record[2] for record in y_val_inp])\n",
    "y_val_data = np.array(list(y_val_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Test Images:\n",
      "\n",
      "ThreadPoolExecutor-0_67: Processing image number: 0\n",
      "ThreadPoolExecutor-0_26: Processing image number: 45\n"
     ]
    }
   ],
   "source": [
    "# Load test set into main memory\n",
    "print('\\nLoading Test Images:\\n')\n",
    "test_data_map = executor.map(get_img_data_parallel, \n",
    "                        [record[0] for record in test_data_inp],\n",
    "                        [record[1] for record in test_data_inp],\n",
    "                        [record[2] for record in test_data_inp])\n",
    "test_data = np.array(list(test_data_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale/normalize images, pixels can have intensity up to 255\n",
    "x_imgs_scaled = x_data / 255.\n",
    "val_imgs_scaled = y_val_data / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the CNN architechture - 4 convolutional layers and 1 fully connected layer\n",
    "# Instantiating the model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(224,224,3)),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    keras.layers.Dense(1024, activation='relu'),\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=x_data.shape[1:]),\n",
    "    keras.layers.Dense(2, activation='softmax'),\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This normalizes labels. Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "le = LabelEncoder()\n",
    "le.fit(x_test)\n",
    "x_test_enc = le.transform(x_test)\n",
    "y_val_test_enc = le.transform(y_val_test)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 16)      448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 220, 220, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 108, 108, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 26, 26, 1024)      132096    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 692224)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1384450   \n",
      "=================================================================\n",
      "Total params: 1,613,986\n",
      "Trainable params: 1,613,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our labels are strings. This is not readable as is, so conversion into numeric form is essential\n",
    "# In other words - converts a class vector (integers), to a binary class matrix\n",
    "# Documentation: https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
    "\n",
    "\n",
    "x_test_enc = to_categorical(x_test_enc)\n",
    "y_val_test_enc = to_categorical(y_val_test_enc)\n",
    "y_val_test_enc.shape\n",
    "x_test_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    opt = keras.optimizers.Adam(learning_rate=hypParam.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before the model can be trained, it needs to be compiled\n",
    "# This will group layers into an object with training features\n",
    "# Documentation: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam.opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative to tensorboard in graphing architecture\n",
    "\n",
    "#import pydotplus\n",
    "#from keras.utils.vis_utils import pydot\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "#keras.utils.vis_utils.pydot = pydot\n",
    "#keras.utils.plot_model(model, \"CNN_graph.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creates directory automatically with date and time stamp for easy navigation\n",
    "# logdir = os.path.join('logs\\\\fit' + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "logdir=\"logs\\\\fit\" # + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "summary = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1, write_graph=True, write_images=False,\n",
    "    update_freq='epoch',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/45\n",
      "144/144 [==============================] - 9s 61ms/sample - loss: 0.6928 - accuracy: 0.5278 - val_loss: 0.6903 - val_accuracy: 0.5278\n",
      "Epoch 2/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6907 - accuracy: 0.5278 - val_loss: 0.6885 - val_accuracy: 0.5278\n",
      "Epoch 3/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6884 - accuracy: 0.5278 - val_loss: 0.6871 - val_accuracy: 0.5278\n",
      "Epoch 4/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6867 - accuracy: 0.5278 - val_loss: 0.6856 - val_accuracy: 0.5278\n",
      "Epoch 5/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6849 - accuracy: 0.5278 - val_loss: 0.6840 - val_accuracy: 0.5278\n",
      "Epoch 6/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6828 - accuracy: 0.5278 - val_loss: 0.6823 - val_accuracy: 0.5278\n",
      "Epoch 7/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6810 - accuracy: 0.5278 - val_loss: 0.6806 - val_accuracy: 0.5278\n",
      "Epoch 8/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6784 - accuracy: 0.5278 - val_loss: 0.6780 - val_accuracy: 0.5278\n",
      "Epoch 9/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6761 - accuracy: 0.5347 - val_loss: 0.6753 - val_accuracy: 0.5278\n",
      "Epoch 10/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6749 - accuracy: 0.6806 - val_loss: 0.6726 - val_accuracy: 0.7222\n",
      "Epoch 11/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6701 - accuracy: 0.6181 - val_loss: 0.6692 - val_accuracy: 0.6111\n",
      "Epoch 12/45\n",
      "144/144 [==============================] - 8s 59ms/sample - loss: 0.6660 - accuracy: 0.6181 - val_loss: 0.6657 - val_accuracy: 0.6111\n",
      "Epoch 13/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6626 - accuracy: 0.5764 - val_loss: 0.6612 - val_accuracy: 0.6389\n",
      "Epoch 14/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6566 - accuracy: 0.6875 - val_loss: 0.6560 - val_accuracy: 0.7500\n",
      "Epoch 15/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6507 - accuracy: 0.7569 - val_loss: 0.6503 - val_accuracy: 0.7778\n",
      "Epoch 16/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6488 - accuracy: 0.7222 - val_loss: 0.6445 - val_accuracy: 0.6389\n",
      "Epoch 17/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6384 - accuracy: 0.7292 - val_loss: 0.6375 - val_accuracy: 0.7500\n",
      "Epoch 18/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6320 - accuracy: 0.7361 - val_loss: 0.6284 - val_accuracy: 0.7778\n",
      "Epoch 19/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6289 - accuracy: 0.7569 - val_loss: 0.6200 - val_accuracy: 0.7222\n",
      "Epoch 20/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.6180 - accuracy: 0.7361 - val_loss: 0.6129 - val_accuracy: 0.7778\n",
      "Epoch 21/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.5999 - accuracy: 0.7917 - val_loss: 0.5979 - val_accuracy: 0.7778\n",
      "Epoch 22/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.5928 - accuracy: 0.8056 - val_loss: 0.5844 - val_accuracy: 0.8333\n",
      "Epoch 23/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.5745 - accuracy: 0.8056 - val_loss: 0.5689 - val_accuracy: 0.8611\n",
      "Epoch 24/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.5635 - accuracy: 0.8056 - val_loss: 0.5521 - val_accuracy: 0.8333\n",
      "Epoch 25/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.5600 - accuracy: 0.7847 - val_loss: 0.5391 - val_accuracy: 0.8056\n",
      "Epoch 26/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.5334 - accuracy: 0.8264 - val_loss: 0.5188 - val_accuracy: 0.8611\n",
      "Epoch 27/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.5120 - accuracy: 0.8472 - val_loss: 0.5031 - val_accuracy: 0.8333\n",
      "Epoch 28/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.5009 - accuracy: 0.8333 - val_loss: 0.4836 - val_accuracy: 0.8889\n",
      "Epoch 29/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.4669 - accuracy: 0.8750 - val_loss: 0.4598 - val_accuracy: 0.8611\n",
      "Epoch 30/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.4647 - accuracy: 0.8542 - val_loss: 0.4456 - val_accuracy: 0.9167\n",
      "Epoch 31/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.4269 - accuracy: 0.8819 - val_loss: 0.4150 - val_accuracy: 0.8611\n",
      "Epoch 32/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.3989 - accuracy: 0.9167 - val_loss: 0.3866 - val_accuracy: 0.8889\n",
      "Epoch 33/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.3797 - accuracy: 0.8958 - val_loss: 0.3855 - val_accuracy: 0.8611\n",
      "Epoch 34/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.3533 - accuracy: 0.9375 - val_loss: 0.3373 - val_accuracy: 0.8611\n",
      "Epoch 35/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.3277 - accuracy: 0.9306 - val_loss: 0.3145 - val_accuracy: 0.9722\n",
      "Epoch 36/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.3171 - accuracy: 0.9583 - val_loss: 0.2977 - val_accuracy: 0.8889\n",
      "Epoch 37/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.2936 - accuracy: 0.9444 - val_loss: 0.2958 - val_accuracy: 0.8889\n",
      "Epoch 38/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.2825 - accuracy: 0.9375 - val_loss: 0.2477 - val_accuracy: 0.9722\n",
      "Epoch 39/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.2408 - accuracy: 0.9722 - val_loss: 0.2269 - val_accuracy: 0.9722\n",
      "Epoch 40/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.2198 - accuracy: 0.9653 - val_loss: 0.2117 - val_accuracy: 0.9722\n",
      "Epoch 41/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.2122 - accuracy: 0.9792 - val_loss: 0.2311 - val_accuracy: 0.8889\n",
      "Epoch 42/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.1846 - accuracy: 0.9792 - val_loss: 0.1725 - val_accuracy: 0.9722\n",
      "Epoch 43/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.1789 - accuracy: 0.9514 - val_loss: 0.1560 - val_accuracy: 0.9722\n",
      "Epoch 44/45\n",
      "144/144 [==============================] - 8s 58ms/sample - loss: 0.1612 - accuracy: 0.9722 - val_loss: 0.1530 - val_accuracy: 1.0000\n",
      "Epoch 45/45\n",
      "144/144 [==============================] - 8s 59ms/sample - loss: 0.1451 - accuracy: 0.9931 - val_loss: 0.1306 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(x_imgs_scaled, x_test_enc, batch_size=hypParam.batch_size, epochs=hypParam.nr_epochs, verbose = hypParam.verbose, validation_data=(val_imgs_scaled, y_val_test_enc), callbacks = [summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9782608695652174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the trained model to predict and calculate the accuracy of the model on the test set that has not been used yet\n",
    "\n",
    "y_pred = model.predict(test_data)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "accuracy_score(y_test_enc, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model, this allows for reusability\n",
    "model.save(modelName.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Closed_Valve       0.95      1.00      0.98        20\n",
      "  Open_Valve       1.00      0.96      0.98        26\n",
      "\n",
      "    accuracy                           0.98        46\n",
      "   macro avg       0.98      0.98      0.98        46\n",
      "weighted avg       0.98      0.98      0.98        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "target_names = ['Closed_Valve' , 'Open_Valve']\n",
    "report=classification_report(y_test_enc,y_pred,target_names=target_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9944), started 2:21:57 ago. (Use '!kill 9944' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-14192787928a2dff\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-14192787928a2dff\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This calls the tensorboard with the desired directory \n",
    "# If it times out during run, just wait a few minutes and run this cell once more\n",
    "\n",
    "# If tensorboard has an error connecting to localhost - which it might have if you restart the computer (it did for me),\n",
    "# follow these steps:\n",
    "# 1) Run cmd\n",
    "# Then type the following on two separate lines\n",
    "# 2) taskkill /im tensorboard.exe /f\n",
    "# 3) del /q %TMP%\\.tensorboard-info\\*\n",
    "\n",
    "%tensorboard --logdir logs\\\\fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
